import enum
import time

from typing import List, Optional, Tuple, Dict, Union, Iterable

from sduss.config import SchedulerConfig
from .policy import PolicyFactory
from .wrappers import Request, RequestStatus, InferenceStage
from sduss.logger import init_logger

logger = init_logger(__name__)

class PreemptionMode(enum.Enum):
    """Preemption Modes

    Attributes:
        SWAP: Swap out the blocks of the preempted sequences to CPU memory
            and swap the back in when the sequences are resumed.
        RECOMPUTE: Discard the blocks of the preempted sequences and recompute
            them when the sequences are resumed, treating the sequences as
            new prompts.
    """
    SWAP = enum.auto()
    RECOMPUTE  = enum.auto()

class SchedulerOutput:    
    """Wrapper of scheduler output.
    
    Args:
        scheduled_requests: List[Request]
            Requests to run in next iteration.
        stage: InferenceStage
            The inference stage at which the selected requests are. All the
            selected requests must be in the same stage.
    """
    
    def __init__(
        self,
        scheduled_requests: List[Request],
        stage: InferenceStage,
    ) -> None:
        self.scheduled_requests = scheduled_requests  
        self.stage = stage  
    
        
class Scheduler:
    """Main scheduler which arranges tasks.
    
    Attributes:
        prompt_limit: Length limit of the prompt derived from configuration.
    """
    
    def __init__(
        self,
        scheduler_config: SchedulerConfig,
    ) -> None:
        self.scheduler_config = scheduler_config
        self.max_batchsize = scheduler_config.max_batchsize
        
        # Scheduler policy
        self.policy = PolicyFactory.get_policy(policy_name="fcfs")
        
        # Sequence groups in the WAITING state. Haven't started to run.
        self.waiting: List[Request] = []
        # Sequence groups in the RUNNING state.
        self.running: List[Request] = []
        # Sequence groups in the SWAPPED state.
        self.swapped: List[Request] = []
        
    def add_request(self, req: Request) -> None:
        """Add a new request to waiting queue."""
        self.waiting.append(req)
        
    def abort_request(self, request_ids: Union[int, Iterable[int]]) -> None:
        """Abort a handful of requests.

        Args:
            request_ids (Union[str, Iterable[str]]): Requests to be aborted.
        """        
        if isinstance(request_ids, int):
            request_ids = (request_ids, )  # transform into an iterable
        request_ids = set(request_ids)
        
        for state_queue in [self.running, self.waiting, self.swapped]:
            # To perform removal correctly, we have to iterate reversely.
            for req in reversed(state_queue):
                if req.request_id in request_ids:
                    state_queue.remove(req)  # Untrack
                    req.status = RequestStatus.FINISHED_ABORTED
                    request_ids.remove(req.request_id)
                    if not request_ids:  # early exit
                        return

        
    def free_finished_requests(self) -> None:
        """Untrack all finished requests."""
        self.running = [
            req for req in self.running
            if not req.is_finished()
        ]
    
    def has_unfinished_requests(self) -> bool:
        return self.waiting or self.running or self.swapped

    def get_num_unfinished_requests(self) -> int:
        return len(self.waiting) + len(self.running) + len(self.swapped)
    
    def _schedule(self) -> SchedulerOutput:
        """Schedules running and swapping operations.

        Returns:
            SchedulerOutputs: All information generated by scheduling.
        """        

        # Fix the current time
        now = time.monotonic()
        
        # TODO(MX): Currently we assume that 1 req has only one Image
        num_collected_req = 0
        
            
        


        scheduler_outputs = SchedulerOutput(
            scheduled_seq_groups=self.running,
            prompt_run=False,
            num_batched_tokens=num_batched_tokens,
            blocks_to_swap_in=blocks_to_swap_in,
            blocks_to_swap_out=blocks_to_swap_out,
            blocks_to_copy=blocks_to_copy,
            ignored_seq_groups=[],
        )
        return scheduler_outputs
                
            
    def schedule(self) -> Tuple[List[SequenceGroupMetadata], SchedulerOutputs]:
        """Schedule sequence groups.
        
        This call will change the status of seq_groups.

        Returns:
            Tuple[List[SequenceGroupMetadata], SchedulerOutputs]: Scheduled 
                sequence groups' metadata and scheduler's output.
            
        """
        scheduler_outputs = self._schedule()
        
        # Create input data structures.
        seq_group_metadata_list: List[SequenceGroupMetadata] = []
        for seq_group in scheduler_outputs.scheduled_seq_groups:
            seq_data: Dict[int, SequenceData] = {}
            physical_blocks_number: Dict[int, List[int]] = {}
            
            for seq in seq_group.get_seqs(status=SequenceStatus.RUNNING):
                seq_id = seq.seq_id
                seq_data[seq_id] = seq.data
                physical_blocks_number[seq_id] = self.block_manager.get_block_table(seq)
            
            seq_group_metadata = SequenceGroupMetadata(
                request_id=seq_group.request_id,
                is_prompt=scheduler_outputs.prompt_run,
                seq_data=seq_data,
                sampling_params=seq_group.sampling_params,
                block_tables=physical_blocks_number,
            )
            seq_group_metadata_list.append(seq_group_metadata)
        
        return seq_group_metadata_list, scheduler_outputs
        

 